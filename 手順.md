# モデル作成手順

### 1. Label Studioのインストール
[公式ドキュメント](https://labelstud.io/guide/quick_start)を参考にインストール。<br>
Python環境で以下のコマンドを実行。
```bash
# インストール
pip install label-studio
# Label Studioの起動
label-studio start
```

### 2. 前処理：写真撮影とトリミングとリサイズ
学習させる画像を1種類につき100枚以上撮影する。<br>
YOLOv8ではデフォルトで640x640の画像サイズで学習するためトリミングとリサイズを行う。<br>
以下はリサイズするためのpythonコードの例。
```py
import glob
from PIL import Image

image_paths = glob.glob('./original/*')
for image_path in image_paths:
    # 画像のトリミングとリサイズ
    img = Image.open(image_path)
    width, height = img.size
    if width > height:
        # 左右をトリミングして正方形にする
        left = (width - height) / 2
        right = left + height
        img = img.crop((left, 0, right, height))
    elif height > width:
        # 上下をトリミングして正方形にする（必要に応じて）
        top = (height - width) / 2
        bottom = top + width
        img = img.crop((0, top, width, bottom))
    # 640x640にリサイズ
    img_resize = img.resize((640, 640))
    img_name = './resized/' + image_path.split('\\')[-1]
    img_resize.save(img_name)
```

### 3. Label Studioでラベリング
リサイズした画像をLabelStudioでラベリングする。<br>
ラベリングが完了したら、YOLO形式でエクスポートする。<br>
[参考サイト](https://qiita.com/hirekatsu0523/items/f2f0e1a0f8a9ea92d913)

### 4. 学習用データを配置
ダウンロードしたラベリング済みデータを配置する。<br>
`datasets` フォルダを作成して `train` と `valid` フォルダを作成する。<br>
`train` に全ての `images` と `labels` を移動する。<br>
全体の20%のデータを `valid` へ移動する。<br>
`classes.txt` と `notes.json` は `datasets` 直下に入れる。<br>
```
datasets/
    train/
        images/
        labels/

    valid/
        images/
        labels/

    classes.txt
    notes.json

data.yaml
```
`data.yaml` は以下の内容で作成した。([参考](https://qiita.com/hirekatsu0523/items/f2f0e1a0f8a9ea92d913#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%81%AE%E4%BD%9C%E6%88%90))
```yaml
train: ./train/images/
val: ./valid/images/

nc: 37 # クラス数
names: ['1m','1p','1s','2m','2p','2s','3m','3p','3s','4m','4p','4s','5m','5m_red','5p','5p_red','5s','5s_red','6m','6p','6s','7m','7p','7s','8m','8p','8s','9m','9p','9s','chun','haku','hatsu','nan','pei','sha','ton']
```

### 5. ultralyticsのインストール
YOLOv8をインストールする。
```
pip install ultralytics
```
https://github.com/ultralytics/ultralytics

### 6. CUDA確認
学習にGPUを利用する場合、CUDAが使用できるか確認する。<br>
セットアップされていない場合はGPUに適したpytorchとCUDAをインストールする。<br>
https://pytorch.org/get-started/previous-versions/<br>
https://note.com/oyasai123/n/n08ac06ea2691
```py
import torch
print(torch.cuda.is_available()) # 出力 true ならOK
torch.cuda.current_device()      # 出た数字は覚えておく
```

### 7. モデル構築
YOLOv8のモデルを作成する。<br>
プリトレーニング済みのモデルとしてyolov8nという一番軽いモデルを選択する。<br>
`data` : data.yamlがあるパス<br>
`epochs` : データセットを何度繰り返して学習するか<br>
`batch` : データセットをバッチ単位で分割して処理する<br>
`device` : GPUを使用する場合に指定する（数字は`torch.cuda.current_device()`で確認した数字）
```py
from ultralytics import YOLO
model = YOLO("yolov8n.pt")
model.train(data='./data.yaml', epochs=600, batch=30, device=0)
```

### 8. Android向けにTensorFlow方式に変換する
Androidで使うためにTFLite形式にエクスポートする。<br>
tensorflowとonnxライブラリが必要。<br>
バージョンによっては変換できないため相性のいいバージョンを導入する。<br>
```
pip install tensorflow==2.16.1
pip install onnx==1.16.1
```
作成したYOLOモデルを指定して変換する。<br>
`device=0` はGPUを使用する場合。
```py
# tflileへ変換
from ultralytics import YOLO
# import yaml
ex_model = YOLO('./runs/detect/train/weights/best.pt')
ex_model.export(format="tflite",data="./data.yaml",device=0)
```
変換したモデルは `./runs/detect/train/weights/best_saved_model/best_float32.tflite`


### 9. テストコード
YOLOモデルを利用してウェブカメラの映像から検出するコード。<br>
```py
import cv2
from ultralytics import YOLO

# モデルをロード
vd_model = YOLO('./runs/detect/train/weights/best.pt')  # best.ptまでの相対パス

# ウェブカメラをキャプチャ
cap = cv2.VideoCapture(0)  # 0はデフォルトのカメラデバイスID

if not cap.isOpened():
    print("ウェブカメラを開くことができませんでした。")
    exit()

print("リアルタイム物体検出を開始します。'q'キーを押すと終了します。")

while True:
    ret, frame = cap.read()
    if not ret:
        print("フレームを取得できませんでした。")
        break

    # 物体検出を実行
    results = vd_model.predict(frame, conf=0.75)

    # 検出結果を画像にプロット
    annotated_frame = results[0].plot()

    # 映像を表示
    cv2.imshow('YOLOリアルタイム検出', annotated_frame)

    # 'q'キーが押されたらループを抜ける
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# リソースを解放
cap.release()
cv2.destroyAllWindows()
print("リアルタイム物体検出を終了しました。")
```
<br>

# アプリ作成手順
以下のリポジトリを参考にしてAndroid Studioで開発を行う。<br>
https://github.com/surendramaran/YOLO/tree/main/YOLOv8-Object-Detector-Android-Tflite